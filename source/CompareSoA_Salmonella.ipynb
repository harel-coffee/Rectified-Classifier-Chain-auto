{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Laod data\n",
    "df = pd.read_csv('Finalplfam_id_Multilabel_Salmonella_data.csv', dtype=str, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labeldf = pd.read_csv('AMR_LAbel_Salmonella.csv',index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ycolumns=Labeldf.columns.values\n",
    "Ycolumns=Ycolumns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genome_id',\n",
       " 'genome_name',\n",
       " 'taxon_id',\n",
       " 'amoxicillin_clavulanic_acid',\n",
       " 'ampicillin',\n",
       " 'azithromycin',\n",
       " 'cefoxitin',\n",
       " 'ceftiofur',\n",
       " 'chloramphenicol',\n",
       " 'ciprofloxacin',\n",
       " 'gentamicin',\n",
       " 'kanamycin',\n",
       " 'nalidixic_acid',\n",
       " 'streptomycin',\n",
       " 'sulfonamides',\n",
       " 'tetracycline',\n",
       " 'trimethoprim_sulphamethoxazole',\n",
       " 'spectinomycin',\n",
       " 'trimethoprim',\n",
       " 'ceftazidime',\n",
       " 'ceftriaxone',\n",
       " 'sulfisoxazole',\n",
       " 'netilmicin',\n",
       " 'cephalosporins',\n",
       " 'furazolidone']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ycolumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df[Ycolumns]\n",
    "Y=Y.drop(columns=['genome_id', 'genome_name','taxon_id'])\n",
    "\n",
    "X=df.drop(columns=Ycolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ycolumns=Y.columns.values\n",
    "Ycolumns=Ycolumns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     amoxicillin_clavulanic_acid  ampicillin  azithromycin  cefoxitin  \\\n",
      "0                           1883      2247.0        2289.0       2070   \n",
      "-1                          1589       167.0        1599.0       1498   \n",
      "1                            401      1516.0          49.0        336   \n",
      "0.5                           64         NaN           NaN         33   \n",
      "\n",
      "     ceftiofur  chloramphenicol  ciprofloxacin  gentamicin  kanamycin  \\\n",
      "0         1863             2963           2733        2358     1027.0   \n",
      "-1        1673              190            210        1251     2830.0   \n",
      "1          400              770            627         314       80.0   \n",
      "0.5          1                8            131          14        NaN   \n",
      "\n",
      "     nalidixic_acid  ...  tetracycline  trimethoprim_sulphamethoxazole  \\\n",
      "0              2650  ...          1351                          2698.0   \n",
      "-1              797  ...           982                           858.0   \n",
      "1               260  ...          1601                           375.0   \n",
      "0.5               1  ...             3                             NaN   \n",
      "\n",
      "     spectinomycin  trimethoprim  ceftazidime  ceftriaxone  sulfisoxazole  \\\n",
      "0            213.0         586.0        231.0       2382.0         1370.0   \n",
      "-1          3437.0        3237.0       3697.0       1143.0         1821.0   \n",
      "1            287.0         114.0          9.0        412.0          746.0   \n",
      "0.5            NaN           NaN          NaN          NaN            NaN   \n",
      "\n",
      "     netilmicin  cephalosporins  furazolidone  \n",
      "0         351.0           262.0         281.0  \n",
      "-1       3576.0          3674.0        3647.0  \n",
      "1          10.0             NaN           9.0  \n",
      "0.5         NaN             NaN           NaN  \n",
      "\n",
      "[4 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "###Data distribution check\n",
    "for index, label in enumerate(Ycolumns):\n",
    "    V= Y[label].value_counts()\n",
    "    if(index==0):\n",
    "        df_val_counts = pd.DataFrame(V)\n",
    "    else:\n",
    "        df_val_counts_t = pd.DataFrame(V)\n",
    "        df_val_counts = df_val_counts.join(df_val_counts_t)\n",
    "        \n",
    "print (df_val_counts)\n",
    "df_val_counts.to_csv('Input_Label_Supplementry_Sal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=X.drop(columns=['amoxicillin/clavulanic acid', 'aztreonam', 'cefepime', 'cefotaxime', 'piperacillin/tazobactam', 'sulfamethoxazole/trimethoprim', 'tobramycin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ycolumns=Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labellist=Ycolumns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5)\n",
    "scorelist=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.fillna(0)\n",
    "X = X.apply(pd.to_numeric)\n",
    "Y = Y.replace(to_replace=[0.5], value=[1])\n",
    "Y = Y.replace(to_replace=['0.5'], value=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_score(y_pred,y_true):\n",
    "    i=0\n",
    "    scorelist=[]\n",
    "    for  amrtrue in y_true:\n",
    "        match=0.0\n",
    "        total=0.0\n",
    "        #print(amrtrue, y_pred[i])\n",
    "        j=0\n",
    "        for trueentry in amrtrue:\n",
    "            #print(trueentry)\n",
    "            if (trueentry == y_pred[i][j]):\n",
    "                #print ('match found')\n",
    "                match=match+1\n",
    "                total=total+1\n",
    "            elif (not (np.isnan(trueentry))):\n",
    "                total = total + 1\n",
    "            j=j+1\n",
    "        i=i+1\n",
    "        #print (match, total, (match/total))\n",
    "        scorelist.append(match/total)\n",
    "    return np.mean(scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def Modified_F1_Score(y_pred,y_true):\n",
    "    #i=0\n",
    "    scorelist=[]\n",
    "    for  i,amrtrue in enumerate(y_true):\n",
    "        TP,FP,TN,FN=0.00000001,0.00000001,0.00000001,0.00000001\n",
    "        #j=0\n",
    "        for j,trueentry in enumerate(amrtrue):\n",
    "            if ((np.isnan(trueentry))):\n",
    "                continue\n",
    "            elif ((trueentry == 1) and (y_pred[i][j]==1)):\n",
    "                TP=TP+1\n",
    "            elif ((trueentry == 1) and (y_pred[i][j]==0)):\n",
    "                FN=FN+1\n",
    "            elif ((trueentry == 0) and (y_pred[i][j]==0)):\n",
    "                TN=TN+1\n",
    "            elif ((trueentry == 0) and (y_pred[i][j]==1)):\n",
    "                FP=FP+1\n",
    "            #j=j+1\n",
    "        #i=i+1\n",
    "        precision=TP/(TP+FP)\n",
    "        recall=TP/(TP+FN)\n",
    "        fscore=(2*precision*recall)/(precision+recall)\n",
    "        scorelist.append(fscore)\n",
    "    return np.mean(scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "sb.set_context(\"talk\")\n",
    "def plot_coefficients(feature_names, coef, name, top_features=20):\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    #top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients =top_positive_coefficients# np.hstack([top_positive_coefficients])\n",
    "    # create plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Feature Importances Multi AMR for \"+str(name), y=1.08)\n",
    "    colors = ['crimson' if c < 0 else 'cornflowerblue' for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(1 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(0, 1 * top_features), feature_names[top_coefficients], rotation=60, ha='right')\n",
    "    plt.show()\n",
    "    np.asarray(feature_names)[top_positive_coefficients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Base models\n",
    "xgbmodel = XGBClassifier(eta=0.0625, max_depth=16, eval_metric='mlogloss', seed=20211028)\n",
    "adaboostmodel = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "modellist=[xgbmodel,adaboostmodel]\n",
    "namelist=['xgb','AdaBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "times=[]\n",
    "methods=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y.replace(to_replace=['IS','Not defined'], value=[np.nan,np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryRelevanceModel(X,Y,kfold, basemodel, name, times, methods):\n",
    "    classifier = BinaryRelevance(basemodel)\n",
    "    hammingscorelist=[]\n",
    "    fscorelist=[]\n",
    "    for train_index, test_index in kfold.split(X, Y):\n",
    "        start = time.process_time()\n",
    "        # split data into train/test sets\n",
    "        x_train_tfidf = X.iloc[train_index]\n",
    "        y_train_tfidf = Y.iloc[train_index]\n",
    "        x_test_tfidf = X.iloc[test_index]\n",
    "        y_test_tfidf = Y.iloc[test_index]\n",
    "        y_train_tfidf=y_train_tfidf.fillna(0)\n",
    "        y_train_tfidf = y_train_tfidf.apply(pd.to_numeric)\n",
    "        y_train_tfidf=y_train_tfidf.astype(int)\n",
    "        y_test_tfidf = y_test_tfidf.apply(pd.to_numeric)\n",
    "        #y_test_tfidf=y_test_tfidf.astype(int)\n",
    "        classifier.fit(x_train_tfidf.values, y_train_tfidf.values)\n",
    "        # calculating test accuracy\n",
    "        prediction = classifier.predict(x_test_tfidf.values)\n",
    "        hammingscore=hamming_score(prediction.toarray(),y_test_tfidf.values)\n",
    "        fscore=Modified_F1_Score(prediction.toarray(),y_test_tfidf.values)\n",
    "        print(fscore, hammingscore)\n",
    "        hammingscorelist.append(hammingscore)\n",
    "        fscorelist.append(fscore)\n",
    "        times = np.append(times, (time.process_time() - start))\n",
    "        methods = np.append(methods, 'BR-'+name)\n",
    "    print ('Base model for BR is {}'.format(name))\n",
    "    print('Test Hamming accuracy for Binary relvance is {}'.format(np.mean(hammingscorelist)))\n",
    "    print('Test F-score accuracy for Binary relvance is {}'.format(np.mean(fscorelist)))\n",
    "    print('Hamming std'+str(np.std(hammingscorelist)))\n",
    "    print('F-Score std'+str(np.std(fscorelist)))\n",
    "    return np.mean(hammingscorelist),np.mean(fscorelist),np.std(hammingscorelist),np.std(fscorelist), times, methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for basemodel in modellist:\n",
    "    hamming, fscore, hmstd, fstd, times, methods=BinaryRelevanceModel(X,Y,kfold,basemodel,namelist[i], times, methods)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing low variance:  (3937, 16358)\n",
      "After removing low variance:  (3937, 7063)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before removing low variance: \", X.shape)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "selector.fit_transform(X)\n",
    "X = X[X.columns[selector.get_support()]].copy()\n",
    "print(\"After removing low variance: \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RectifiedClassifierChain import RectifiedClassiferChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amoxicillin_clavulanic_acid</th>\n",
       "      <th>ampicillin</th>\n",
       "      <th>cefoxitin</th>\n",
       "      <th>ceftiofur</th>\n",
       "      <th>chloramphenicol</th>\n",
       "      <th>ciprofloxacin</th>\n",
       "      <th>gentamicin</th>\n",
       "      <th>kanamycin</th>\n",
       "      <th>nalidixic_acid</th>\n",
       "      <th>streptomycin</th>\n",
       "      <th>sulfonamides</th>\n",
       "      <th>tetracycline</th>\n",
       "      <th>trimethoprim_sulphamethoxazole</th>\n",
       "      <th>spectinomycin</th>\n",
       "      <th>trimethoprim</th>\n",
       "      <th>ceftriaxone</th>\n",
       "      <th>sulfisoxazole</th>\n",
       "      <th>cephalosporins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     amoxicillin_clavulanic_acid ampicillin cefoxitin ceftiofur  \\\n",
       "0                              1          1         1         1   \n",
       "1                            NaN          1       NaN       NaN   \n",
       "2                            NaN          0       NaN       NaN   \n",
       "3                              1          1         0         1   \n",
       "4                              0          0         0         0   \n",
       "...                          ...        ...       ...       ...   \n",
       "3932                           1          1         1         1   \n",
       "3933                           0          0         0         0   \n",
       "3934                           0          0       NaN       NaN   \n",
       "3935                         NaN          0       NaN       NaN   \n",
       "3936                         NaN          1         0       NaN   \n",
       "\n",
       "     chloramphenicol ciprofloxacin gentamicin kanamycin nalidixic_acid  \\\n",
       "0                  0             0          0         0              0   \n",
       "1                  1             0          0         0              0   \n",
       "2                  0           NaN        NaN       NaN              0   \n",
       "3                  0             0          1       NaN              0   \n",
       "4                  0             0          0         0              0   \n",
       "...              ...           ...        ...       ...            ...   \n",
       "3932               0             0          0         1              0   \n",
       "3933               0             0          0       NaN              0   \n",
       "3934               0             0          0         0              1   \n",
       "3935               1             0          0         0              0   \n",
       "3936               0             1          1         0              1   \n",
       "\n",
       "     streptomycin sulfonamides tetracycline trimethoprim_sulphamethoxazole  \\\n",
       "0               0          NaN            0                              0   \n",
       "1               1            1            1                            NaN   \n",
       "2             NaN          NaN          NaN                              0   \n",
       "3               1          NaN            1                              0   \n",
       "4               0            0            1                              0   \n",
       "...           ...          ...          ...                            ...   \n",
       "3932            0          NaN            1                              0   \n",
       "3933            0          NaN            0                              0   \n",
       "3934            0          NaN            1                            NaN   \n",
       "3935            1            1            1                            NaN   \n",
       "3936            1            1            1                            NaN   \n",
       "\n",
       "     spectinomycin trimethoprim ceftriaxone sulfisoxazole cephalosporins  \n",
       "0              NaN          NaN           1             0            NaN  \n",
       "1                1            0         NaN           NaN            NaN  \n",
       "2              NaN          NaN         NaN           NaN              0  \n",
       "3              NaN          NaN           1             1            NaN  \n",
       "4              NaN          NaN         NaN           NaN            NaN  \n",
       "...            ...          ...         ...           ...            ...  \n",
       "3932           NaN          NaN           1             1            NaN  \n",
       "3933           NaN          NaN           0             0            NaN  \n",
       "3934           NaN            0         NaN           NaN            NaN  \n",
       "3935             1            0         NaN           NaN            NaN  \n",
       "3936             1            0           0           NaN            NaN  \n",
       "\n",
       "[3937 rows x 18 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RCCModelwithMR(X,Y,kfold, basemodel, name, times, methods,shapTotal, type=0):\n",
    "    sim_all_df = pd.DataFrame()\n",
    "    hammingscorelist=[]\n",
    "    fscorelist=[]\n",
    "    for train_index, test_index in kfold.split(X, Y):\n",
    "        # split data into train/test sets\n",
    "        start = time.process_time()\n",
    "        x_train_tfidf = X.iloc[train_index]\n",
    "        y_train_tfidf = Y.iloc[train_index]\n",
    "        x_test_tfidf = X.iloc[test_index]\n",
    "        y_test_tfidf = Y.iloc[test_index]\n",
    "        x_train_tfidf=x_train_tfidf.reset_index(drop=True)\n",
    "        y_train_tfidf=y_train_tfidf.reset_index(drop=True)\n",
    "        y_train_tfidf = y_train_tfidf.apply(pd.to_numeric)\n",
    "        #y_train_tfidf=y_train_tfidf.astype(int)\n",
    "        y_test_tfidf = y_test_tfidf.apply(pd.to_numeric)\n",
    "        classifier=RectifiedClassiferChain(basemodel,optimized=True,optimizedmethod='MissingRatio')\n",
    "        classifier.trainRCC(x_train_tfidf, y_train_tfidf)\n",
    "        # calculating test accuracy\n",
    "        x_test_tfidf=x_test_tfidf.reset_index(drop=True)\n",
    "        y_test_tfidf=y_test_tfidf.reset_index(drop=True)\n",
    "        prediction = classifier.predictRCC(x_test_tfidf)\n",
    "        hammingscore, fscore=classifier.Evaluate(y_test_tfidf,prediction)\n",
    "        \n",
    "        #hammingscore1=hamming_score(np.array(prediction),y_test_tfidf.values)\n",
    "        #fscore1=Modified_F1_Score(np.array(prediction),y_test_tfidf.values)\n",
    "        \n",
    "        print(hammingscore,fscore)\n",
    "        #print(hammingscore1,fscore1)\n",
    "        hammingscorelist.append(hammingscore)\n",
    "        fscorelist.append(fscore)\n",
    "        times = np.append(times, (time.process_time() - start))\n",
    "        methods = np.append(methods, 'RCC_MR-'+name)\n",
    "        label_order=classifier.getOptimizedLabelOrder()\n",
    "        print (label_order)\n",
    "        if(type !=2):\n",
    "            featuredf=classifier.getFeature(NoOfFeature=100,type=type,full=True)\n",
    "            #featuredf.to_csv('Test.csv')\n",
    "            sim_all_df = pd.concat([sim_all_df, featuredf], ignore_index=True)\n",
    "        if(type==3):\n",
    "            shapValue=classifier.getShapFeatures()\n",
    "            shapTotal.append(shapValue)\n",
    "    print ('Base model for RCC is {}'.format(name))\n",
    "    print('Test Hamming accuracy for RCC is {}'.format(np.mean(hammingscorelist)))\n",
    "    print('Test F-score accuracy for RCC is {}'.format(np.mean(fscorelist)))\n",
    "    print('Hamming std'+str(np.std(hammingscorelist)))\n",
    "    print('F-Score std'+str(np.std(fscorelist)))\n",
    "    if(type !=2):\n",
    "        sim_all_df_T = sim_all_df.transpose().copy()\n",
    "        sim_all_df_T[\"feature_weight_sum\"] = sim_all_df_T.apply(lambda x: abs(x).sum(), axis=1)\n",
    "        sim_all_df_T_top = sim_all_df_T.sort_values(\"feature_weight_sum\", ascending=False)[:30]\n",
    "        #sim_all_df_T_top.to_csv('Test.csv')\n",
    "    else:\n",
    "        sim_all_df_T_top=sim_all_df.copy()\n",
    "    return np.mean(hammingscorelist),np.mean(fscorelist),sim_all_df_T_top, times, methods, shapTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "modellist=[xgbmodel]\n",
    "namelist=['xgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/users/mt01034/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The target 'y' needs to have more than 1 class. Got 1 class instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46531/3045485438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mhamming\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturedf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTotShape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRCCModelwithMR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTotShape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfeaturedf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sim_all_df_T_RCC_MR_Sal'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_46531/2203658879.py\u001b[0m in \u001b[0;36mRCCModelwithMR\u001b[0;34m(X, Y, kfold, basemodel, name, times, methods, shapTotal, type)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0my_test_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRectifiedClassiferChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizedmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MissingRatio'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainRCC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# calculating test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx_test_tfidf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MTM/NewData/RectifiedClassifierChain.py\u001b[0m in \u001b[0;36mtrainRCC\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mYtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0moversample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2021\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mXtrainOver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrainOver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moversample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mmodelc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrainOver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrainOver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdroppedindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampling_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MTM/NewData/ML4AMR/lib/python3.7/site-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36mcheck_sampling_strategy\u001b[0;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         raise ValueError(\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0;34mf\"The target 'y' needs to have more than 1 class. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;34mf\"Got {np.unique(y).size} class instead\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The target 'y' needs to have more than 1 class. Got 1 class instead"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "TotShape=[]\n",
    "for basemodel in modellist:\n",
    "    if(namelist[i] =='AdaBoost'):\n",
    "        type=1\n",
    "    elif(namelist[i] =='xgb'):\n",
    "        type=3\n",
    "    elif(namelist[i] =='Gaussian'):\n",
    "        type=2\n",
    "    else:\n",
    "        type=0\n",
    "    hamming, fscore, featuredf, times, methods, TotShape=RCCModelwithMR(X,Y,kfold,basemodel,namelist[i], times, methods, TotShape, type)\n",
    "    if(type!=2):\n",
    "        featuredf.to_csv('sim_all_df_T_RCC_MR_Sal'+str(namelist[i])+'.csv')\n",
    "        #print(featuredf)\n",
    "        plot_coefficients(list(featuredf.index),featuredf[\"feature_weight_sum\"],namelist[i],30)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RCCModelwithCP(X,Y,kfold, basemodel, name, times, methods,shapTotal, type=0):\n",
    "    sim_all_df = pd.DataFrame()\n",
    "    hammingscorelist=[]\n",
    "    fscorelist=[]\n",
    "    for train_index, test_index in kfold.split(X, Y):\n",
    "        # split data into train/test sets\n",
    "        start = time.process_time()\n",
    "        x_train_tfidf = X.iloc[train_index]\n",
    "        y_train_tfidf = Y.iloc[train_index]\n",
    "        x_test_tfidf = X.iloc[test_index]\n",
    "        y_test_tfidf = Y.iloc[test_index]\n",
    "        x_train_tfidf=x_train_tfidf.reset_index(drop=True)\n",
    "        y_train_tfidf=y_train_tfidf.reset_index(drop=True)\n",
    "        y_train_tfidf = y_train_tfidf.apply(pd.to_numeric)\n",
    "        #y_train_tfidf=y_train_tfidf.astype(int)\n",
    "        y_test_tfidf = y_test_tfidf.apply(pd.to_numeric)\n",
    "        classifier=RectifiedClassiferChain(basemodel,optimized=True,optimizedmethod='ConditionalProb')\n",
    "        classifier.trainRCC(x_train_tfidf, y_train_tfidf)\n",
    "        # calculating test accuracy\n",
    "        x_test_tfidf=x_test_tfidf.reset_index(drop=True)\n",
    "        y_test_tfidf=y_test_tfidf.reset_index(drop=True)\n",
    "        prediction = classifier.predictRCC(x_test_tfidf)\n",
    "        hammingscore, fscore=classifier.Evaluate(y_test_tfidf,prediction)\n",
    "        \n",
    "        #hammingscore1=hamming_score(np.array(prediction),y_test_tfidf.values)\n",
    "        #fscore1=Modified_F1_Score(np.array(prediction),y_test_tfidf.values)\n",
    "        \n",
    "        print(hammingscore,fscore)\n",
    "        #print(hammingscore1,fscore1)\n",
    "        hammingscorelist.append(hammingscore)\n",
    "        fscorelist.append(fscore)\n",
    "        times = np.append(times, (time.process_time() - start))\n",
    "        methods = np.append(methods, 'RCC_CE-'+name)\n",
    "        label_order=classifier.getOptimizedLabelOrder()\n",
    "        print (label_order)\n",
    "        if(type !=2):\n",
    "            featuredf=classifier.getFeature(NoOfFeature=100,type=type,full=True)\n",
    "            #featuredf.to_csv('Test.csv')\n",
    "            sim_all_df = pd.concat([sim_all_df, featuredf], ignore_index=True)\n",
    "        if(type==3):\n",
    "            shapValue=classifier.getShapFeatures()\n",
    "            shapTotal.append(shapValue)\n",
    "    print ('Base model for RCC is {}'.format(name))\n",
    "    print('Test Hamming accuracy for RCC is {}'.format(np.mean(hammingscorelist)))\n",
    "    print('Test F-score accuracy for RCC is {}'.format(np.mean(fscorelist)))\n",
    "    print('Hamming std'+str(np.std(hammingscorelist)))\n",
    "    print('F-Score std'+str(np.std(fscorelist)))\n",
    "    if(type !=2):\n",
    "        sim_all_df_T = sim_all_df.transpose().copy()\n",
    "        sim_all_df_T[\"feature_weight_sum\"] = sim_all_df_T.apply(lambda x: abs(x).sum(), axis=1)\n",
    "        sim_all_df_T_top = sim_all_df_T.sort_values(\"feature_weight_sum\", ascending=False)[:30]\n",
    "        #sim_all_df_T_top.to_csv('Test.csv')\n",
    "    else:\n",
    "        sim_all_df_T_top=sim_all_df.copy()\n",
    "    return np.mean(hammingscorelist),np.mean(fscorelist),sim_all_df_T_top, times, methods, shapTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "TotShape=[]\n",
    "for basemodel in modellist:\n",
    "    if(namelist[i] =='AdaBoost'):\n",
    "        type=1\n",
    "    elif(namelist[i] =='xgb'):\n",
    "        type=3\n",
    "    elif(namelist[i] =='Gaussian'):\n",
    "        type=2\n",
    "    else:\n",
    "        type=0\n",
    "    hamming, fscore, featuredf, times, methods, TotShape=RCCModelwithCP(X,Y,kfold,basemodel,namelist[i], times, methods, TotShape, type)\n",
    "    if(type!=2):\n",
    "        featuredf.to_csv('sim_all_df_T_RCC_CP_Sal'+str(namelist[i])+'.csv')\n",
    "        #print(featuredf)\n",
    "        plot_coefficients(list(featuredf.index),featuredf[\"feature_weight_sum\"],namelist[i],30)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StackedClassifierChain import StackedClassifierChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCCModelwithSSC(X,Y,kfold, basemodel, name, times, methods, type=0):\n",
    "    sim_all_df = pd.DataFrame()\n",
    "    hammingscorelist=[]\n",
    "    fscorelist=[]\n",
    "    for train_index, test_index in kfold.split(X, Y):\n",
    "        # split data into train/test sets\n",
    "        start = time.process_time()\n",
    "        x_train_tfidf = X.iloc[train_index]\n",
    "        y_train_tfidf = Y.iloc[train_index]\n",
    "        x_test_tfidf = X.iloc[test_index]\n",
    "        y_test_tfidf = Y.iloc[test_index]\n",
    "        x_train_tfidf=x_train_tfidf.reset_index(drop=True)\n",
    "        y_train_tfidf=y_train_tfidf.reset_index(drop=True)\n",
    "        y_train_tfidf=y_train_tfidf.fillna(0)\n",
    "        y_train_tfidf = y_train_tfidf.apply(pd.to_numeric)\n",
    "        y_train_tfidf=y_train_tfidf.astype(int)\n",
    "        y_test_tfidf = y_test_tfidf.apply(pd.to_numeric)\n",
    "        classifier=StackedClassifierChain(basemodel)\n",
    "        classifier.trainSCC(x_train_tfidf, y_train_tfidf)\n",
    "        # calculating test accuracy\n",
    "        x_test_tfidf=x_test_tfidf.reset_index(drop=True)\n",
    "        y_test_tfidf=y_test_tfidf.reset_index(drop=True)\n",
    "        prediction = classifier.predictSCC(x_test_tfidf)\n",
    "        hammingscore, fscore=classifier.Evaluate(y_test_tfidf,prediction)\n",
    "        \n",
    "        #hammingscore1=hamming_score(np.array(prediction),y_test_tfidf.values)\n",
    "        #fscore1=Modified_F1_Score(np.array(prediction),y_test_tfidf.values)\n",
    "        \n",
    "        print(hammingscore,fscore)\n",
    "        #print(hammingscore1,fscore1)\n",
    "        hammingscorelist.append(hammingscore)\n",
    "        fscorelist.append(fscore)\n",
    "        times = np.append(times, (time.process_time() - start))\n",
    "        methods = np.append(methods, 'SCC-'+name)\n",
    "        if(type !=2):\n",
    "            featuredf=classifier.getFeature(NoOfFeature=100,type=type,full=True)\n",
    "            #featuredf.to_csv('Test.csv')\n",
    "            sim_all_df = pd.concat([sim_all_df, featuredf], ignore_index=True)\n",
    "    print ('Base model for SCC is {}'.format(name))\n",
    "    print('Test Hamming accuracy for SCC is {}'.format(np.mean(hammingscorelist)))\n",
    "    print('Test F-score accuracy for SCC is {}'.format(np.mean(fscorelist)))\n",
    "    print('Hamming std'+str(np.std(hammingscorelist)))\n",
    "    print('F-Score std'+str(np.std(fscorelist)))\n",
    "    if(type !=2):\n",
    "        sim_all_df_T = sim_all_df.transpose().copy()\n",
    "        sim_all_df_T[\"feature_weight_sum\"] = sim_all_df_T.apply(lambda x: abs(x).sum(), axis=1)\n",
    "        sim_all_df_T_top = sim_all_df_T.sort_values(\"feature_weight_sum\", ascending=False)[:30]\n",
    "        sim_all_df_T_top.to_csv('SCCTest.csv')\n",
    "    else:\n",
    "        sim_all_df_T_top=sim_all_df.copy()\n",
    "    return np.mean(hammingscorelist),np.mean(fscorelist),sim_all_df_T_top, times, methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for basemodel in modellist:\n",
    "    if(namelist[i] =='randomforest' or namelist[i] =='xgb' or namelist[i]=='AdaBoost'):\n",
    "        type=1\n",
    "    elif(namelist[i] =='Gaussian'):\n",
    "        type=2\n",
    "    else:\n",
    "        type=0\n",
    "    hamming, fscore, featuredf, times, methods=SCCModelwithSSC(X,Y,kfold,basemodel,namelist[i], times, methods,type)\n",
    "    if(type!=2):\n",
    "        featuredf.to_csv('sim_all_df_T_SCC_SSC_Sal'+str(namelist[i])+'.csv')\n",
    "        #print(featuredf)\n",
    "        plot_coefficients(list(featuredf.index),featuredf[\"feature_weight_sum\"],namelist[i],30)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "XGB -A tree depth of 16 , 10-mers were used to build models from assembled genomes to ensure that all models would fit in memory\n",
    " learning rate was set to 0.0625\n",
    "    column and row subsampling was set to 1.0 \n",
    "     number of rounds of boosting was limited to 1000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "AdaBoost\n",
    "K=31\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##https://journals.asm.org/doi/full/10.1128/JCM.01260-18\n",
    "https://github.com/PATRIC3/mic_prediction\n",
    "    \n",
    "###https://github.com/TahaAslani/AAk-mer\n",
    "https://www.mdpi.com/2079-7737/9/11/365/htm\n",
    "\n",
    "##https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008319\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "#explainer=shap.TreeExplainer(rf_classifier)\n",
    "rf_shap_values = shap.KernelExplainer(rf_classifier.predict,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "prediction=rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(rf_shap_values.expected_value,shap_values,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KErnalExplnanier = shap.TreeExplainer(classifer)\n",
    "svm_shap_values = KErnalExplnanier.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
